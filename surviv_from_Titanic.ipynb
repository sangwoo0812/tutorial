{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# train 행과 열의 수 확인\n",
    "len(train)\n",
    "train.columns\n",
    "\n",
    "train.info()\n",
    "train.describe()\n",
    "\n",
    "# 랜덤으로 생존 여부 생성\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "survived = np.random.randint(0, 2, size=len(submission['Survived']))\n",
    "print(survived)\n",
    "\n",
    "# 랜덤 값 채우기\n",
    "submission['Survived'] = survived\n",
    "submission.head(20)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# 원본 데이터 소실, 변형 막기 위한 복사본 만들기\n",
    "train = raw_data_train.copy()\n",
    "test = raw_data_test.copy()\n",
    "submission = raw_data_submission.copy()\n",
    "\n",
    "# 평균값으로 결측치 대체\n",
    "mean_age = train['Age'].mean()\n",
    "mean_fare = train['Fare'].mean()\n",
    "\n",
    "train['Age'] = train['Age'].fillna(mean_age)\n",
    "train['Fare'] = train['Fare'].fillna(mean_fare)\n",
    "\n",
    "test['Age'] = test['Age'].fillna(mean_age)\n",
    "test['Fare'] = test['Fare'].fillna(mean_fare)\n",
    "\n",
    "# 8:2로 학습/검증 데이터 분리\n",
    "train_x = train.drop(columns='Survived')\n",
    "train_y = train['Survived']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y  = train_test_split(train_x, train_y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 로지스틱 회귀 모델 정의 및 학습\n",
    "import statsmodels.api as sm\n",
    "train_dataset = pd.concat([train_x, train_y], axis=1)\n",
    "\n",
    "formula = \"\"\"\n",
    "Survived ~ Age + SibSp + Parch + Fare\n",
    "\"\"\"\n",
    "\n",
    "model = sm.Logit.from_formula(formula, data=train_dataset)\n",
    "result = model.fit()\n",
    "\n",
    "result.summary()\n",
    "\n",
    "y_pred = result.predict(val_x)\n",
    "y_pred = y_pred.apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_y, y_pred))\n",
    "\n",
    "y_pred = result.predict(test)\n",
    "y_pred = y_pred.apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "submission['Survived'] = y_pred\n",
    "submission.head(15)\n",
    "\n",
    "# 종속변수 시각화\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.countplot(x=raw_data_train['Survived'])\n",
    "plt.show()\n",
    "\n",
    "# 독립변수 시각화\n",
    "columns = ['Pclass', 'Sex', 'Embarked']\n",
    "for col_name in columns:\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(10,5))\n",
    "    sns.countplot(x=raw_data_train[col_name], palette='Set2', ax=ax[0]).set(title=col_name+' count plot')\n",
    "    sns.barplot(data=raw_data_train, x=col_name, y=\"Survived\", palette='Set2', ax=ax[1]).set(title=col_name+' bar chart')\n",
    "    plt.show()\n",
    "\n",
    "raw_data_train['Survived_str'] = raw_data_train['Survived'].apply(lambda x: 'deth' if x == 0 else 'Survive')\n",
    "columns = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "for col_name in columns:\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(13,5))\n",
    "    sns.boxplot(x=raw_data_train[col_name], ax=ax[0], palette='Set2')\n",
    "    sns.boxplot(data=raw_data_train, x=col_name, y=\"Survived_str\", ax=ax[1], palette='Set2')\n",
    "    plt.show()\n",
    "# 결측치 대체\n",
    "train = raw_data_train.copy()\n",
    "test = raw_data_test.copy()\n",
    "submission = raw_data_submission.copy()\n",
    "\n",
    "mean_age = train['Age'].mean()\n",
    "mean_fare = train['Fare'].mean()\n",
    "\n",
    "# ‘Age’ ‘Fare’ feature의 Null 값을 각 feature의 평균(mean)값으로 대체\n",
    "train['Age'] = train['Age'].fillna(mean_age)\n",
    "test['Age'] = test['Age'].fillna(mean_age)\n",
    "train['Fare'] = train['Fare'].fillna(mean_fare)\n",
    "test['Fare'] = test['Fare'].fillna(mean_fare)\n",
    "\n",
    "# 이상치 제거\n",
    "train = train[train['Parch'] <= 5]\n",
    "train = train[train['Fare'] <= 300]\n",
    "\n",
    "train_x = train.drop(columns='Survived')\n",
    "train_y = train['Survived']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y  = train_test_split(train_x, train_y, test_size=0.2, random_state=0)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "train_dataset = train_x.copy()\n",
    "train_dataset['Survived'] = train_y\n",
    "\n",
    "formula = \"\"\"\n",
    "Survived ~ C(Pclass)+ C(Sex) + scale(Age) + scale(SibSp) + scale(Parch) + scale(Fare) + C(Embarked)\n",
    "\"\"\"\n",
    "model = sm.Logit.from_formula(formula, data=train_dataset)  \n",
    "result = model.fit()  \n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "y_pred = result.predict(val_x)\n",
    "y_pred = y_pred.apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_y, y_pred))\n",
    "\n",
    "y_pred = result.predict(test)\n",
    "y_pred = y_pred.apply(lambda x: 1 if x >=0.5 else 0)\n",
    "\n",
    "submission['Survived'] = y_pred\n",
    "submission.head(15)\n",
    "\n",
    "# 원본 데이터 복사\n",
    "train = raw_data_train.copy()\n",
    "test = raw_data_test.copy()\n",
    "submission = raw_data_submission.copy()\n",
    "\n",
    "columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "train = train[columns + ['Survived']]\n",
    "test = test[columns]\n",
    "\n",
    "# Null 처리\n",
    "mean_age = train['Age'].mean()\n",
    "mean_fare = train['Fare'].mean()\n",
    "\n",
    "train.loc[:, 'Age'] = train['Age'].fillna(mean_age)\n",
    "test.loc[:, 'Age'] = test['Age'].fillna(mean_age)\n",
    "train.loc[:, 'Fare'] = train['Fare'].fillna(mean_fare)\n",
    "test.loc[:, 'Fare'] = test['Fare'].fillna(mean_fare)\n",
    "\n",
    "# 이상치 제거\n",
    "train = train[train['Parch'] <= 5]       \n",
    "train = train[train['Fare'] <= 300] \n",
    "\n",
    "train['Sex'] = train['Sex'].apply(lambda x: 0 if x == 'female' else 1)\n",
    "test['Sex'] = test['Sex'].apply(lambda x: 0 if x == 'female' else 1)\n",
    "\n",
    "train = pd.get_dummies(train, columns=['Embarked'], drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "train_x = train.drop(columns=['Survived'])\n",
    "train_y = train[['Survived']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y  = train_test_split(train_x, train_y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 데이터 불균형 해소를 위한 데이터 증강\n",
    "### 소수 데이터와 기존 데이터 사이에 가상 샘플 생성, 소수 클래스가 의미있는 패턴을 가지고 클래스 불균형이 심할때 (1:10) 사용 필요\n",
    "### But 분류 전용으롯 사용되어야 하고, train에만 적용되어야함\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(train_x,train_y)\n",
    "\n",
    "X_resampled['Survived'] = y_resampled\n",
    "train_dataset = X_resampled\n",
    "\n",
    "# 데이터를 질문으로 계속 나누는 분류 모델인 결정트리분류\n",
    "### max_depth는 보통 3~8 사이가 안정적, 과적합 나기 쉬움 3~5(데이터 ~1000), 4~6(데이터 ~10000), 6~8(데이터 100000 이상)\n",
    "### min_samples_leaf로 하나의 최종 규칙이 최소 몇 개 데이터를 가져야 하는지를 다룸 20~50(데이터 ~1000), 50~100(데이터 ~10000), 100~300(데이터 100000 이상)\n",
    "### min_samples_split으로 질문을 허용할 최소 조건 (leaf보다 항상 크거나 같아야함) 50~100(데이터 ~1000), 100~200(데이터 ~10000), 200~500(데이터 100000 이상)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=6, random_state=0)\n",
    "model.fit(train_dataset.drop(columns='Survived'),train_dataset['Survived'])\n",
    "\n",
    "y_pred = model.predict(val_x)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_y, y_pred))\n",
    "\n",
    "y_pred = model.predict(test)  \n",
    "submission['Survived'] = y_pred\n",
    "submission['Survived'] = submission['Survived'].apply(lambda x:1 if x >= 0.5 else 0)  \n",
    "submission.head(15)\n",
    "\n",
    "#------------------한 번에 돌리기---------------\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "train = train[columns + ['Survived']]\n",
    "test = test[columns]\n",
    "\n",
    "# Null 처리\n",
    "mean_age = train['Age'].mean()\n",
    "mean_fare = train['Fare'].mean()\n",
    "\n",
    "train['Age'] = train['Age'].fillna(mean_age)\n",
    "test['Age'] = test['Age'].fillna(mean_age)\n",
    "train['Fare'] = train['Fare'].fillna(mean_fare)\n",
    "test['Fare'] = test['Fare'].fillna(mean_fare)\n",
    "\n",
    "# 이상치 제거\n",
    "train = train[train['Parch'] <= 5]\n",
    "train = train[train['Fare'] <= 300]\n",
    "\n",
    "train['Sex'] = train['Sex'].apply(lambda x: 0 if x == 'female' else 1)\n",
    "test['Sex'] = test['Sex'].apply(lambda x: 0 if x == 'female' else 1)\n",
    "\n",
    "train = pd.get_dummies(train, columns=['Embarked'], drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "train_x = train.drop(columns=['Survived'])\n",
    "train_y = train['Survived']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y  = train_test_split(train_x, train_y, test_size=0.2, random_state=0)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 모델설정\n",
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "# train데이터를 넣어 복제함\n",
    "X_resampled, y_resampled = smote.fit_resample(train_x, train_y)\n",
    "\n",
    "X_resampled['Survived'] = y_resampled\n",
    "train_dataset = X_resampled\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "formula = \"\"\"\n",
    "Survived ~ C(Pclass)+ C(Sex) + scale(Age) + scale(SibSp) + scale(Parch) + scale(Fare) + C(Embarked_Q)+ C(Embarked_S)\n",
    "\"\"\"\n",
    "\n",
    "model = sm.Logit.from_formula(formula, data=train_dataset)\n",
    "result = model.fit()\n",
    "y_pred = result.predict(val_x)\n",
    "y_pred = y_pred.apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(classification_report(val_y, y_pred))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=6, random_state=0)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "y_pred = model.predict(val_x)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(classification_report(val_y, y_pred))\n",
    "\n",
    "# 의사결정나무 여러개를 사용하여 과적합 방지에 탁월하나 속도/메모리 부담 있음\n",
    "### n_estimators는 트리 개수로 100(빠른 베이스라인), 200~300(안정적), 500 이상(성능 미미하고 시간만 늘어남)\n",
    "### max_depth 6~10, 나무가 여러 개라 너무 과한 설정 필요없음\n",
    "### min_samples_leaf, 20~100 데이터 많을수록 키우기\n",
    "### max_feathers, 랜덤성 핵심으로 \"sqrt\"를 거의 쓰면되고, 0.7 등으로 수치 바꿔보며 결과보기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=0)\n",
    "model.fit(train.drop(columns='Survived'),train['Survived'])\n",
    "\n",
    "y_pred = model.predict(val_x)\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(classification_report(val_y, y_pred))\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(n_estimators=200, learning_rate=0.01, max_depth=5, random_state = 0)\n",
    "model.fit(train_x,train_y)\n",
    "y_pred = model.predict(val_x)\n",
    "\n",
    "print(confusion_matrix(val_y, y_pred))\n",
    "print(classification_report(val_y, y_pred))\n",
    "\n",
    "my_model = XGBClassifier(n_estimators=200, learning_rate=0.01, max_depth=5, random_state = 0)\n",
    "my_model.fit(train_dataset.drop(columns='Survived'),train_dataset['Survived'])\n",
    "XGB_pred = my_model.predict(test)\n",
    "\n",
    "y_pred = my_model.predict(test)\n",
    "submission['Survived'] = y_pred\n",
    "submission.head(10)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
