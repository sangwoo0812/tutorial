{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2073913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "result = pd.read_csv('Auction_result.csv')\n",
    "\n",
    "# 데이터 상위 일부 행 확인 및 데이터 구조와 내용 파악\n",
    "train.head(5)\n",
    "# 데이터 프레임의 정보 확인\n",
    "train.info()\n",
    "\n",
    "test.head(4)\n",
    "# 데이터 하위 일부 행 확인\n",
    "submission.tail(2)\n",
    "# 작업 편의성을 위한 데이터 이름 변경\n",
    "train = train.rename(columns={'point.y':'point_y', 'point.x' : 'point_x'})\n",
    "test = test.rename(columns={'point.y':'point_y', 'point.x' : 'point_x'})\n",
    "# 결측값, 문자열을 가지는 데이터 열 제거\n",
    "train = train.drop(labels = ['Auction_key', 'Auction_class', 'Bid_class', 'Appraisal_company', 'Appraisal_date', \n",
    "                'First_auction_date', 'Final_auction_date', 'Final_result', 'Creditor',\n",
    "                'addr_do', 'addr_si', 'addr_dong' , 'addr_li', 'addr_san','addr_bunji1',\n",
    "                'addr_bunji2','addr_etc', 'Apartment_usage', 'Preserve_regist_date', 'Specific', \n",
    "                'Share_auction_YorN', 'road_name', 'road_bunji1', 'road_bunji2', 'Close_date', \n",
    "                'Close_result'], axis = 1)\n",
    "\n",
    "train.head()\n",
    "\n",
    "test = test.drop(labels = ['Auction_key', 'Auction_class', 'Bid_class', 'Appraisal_company', 'Appraisal_date', \n",
    "                'First_auction_date', 'Final_auction_date', 'Final_result', 'Creditor',\n",
    "                'addr_do', 'addr_si', 'addr_dong' , 'addr_li', 'addr_san', 'addr_bunji1',\n",
    "                'addr_bunji2','addr_etc', 'Apartment_usage', 'Preserve_regist_date', 'Specific', \n",
    "                'Share_auction_YorN', 'road_name', 'road_bunji1', 'road_bunji2', 'Close_date', \n",
    "                'Close_result'], axis = 1)\n",
    "\n",
    "test.head()\n",
    "# 예측에 필요한 종속변수 할당\n",
    "original_y = train['Hammer_price']\n",
    "original_y.head()\n",
    "# 학습에 필요한 독립변수 할당\n",
    "features = ['Claim_price', 'Auction_count', 'Auction_miscarriage_count',\n",
    "       'Total_land_gross_area', 'Total_land_real_area',\n",
    "       'Total_land_auction_area', 'Total_building_area',\n",
    "       'Total_building_auction_area', 'Total_appraisal_price',\n",
    "       'Minimum_sales_price', 'Total_floor', 'Current_floor', 'point_y',\n",
    "       'point_x']\n",
    "\n",
    "original_x = train[features]\n",
    "original_x.head()\n",
    "# train set으로 검증하기 위해 train과 valid set으로 분리\n",
    "### test_size는 0.2일때가 디폴트, 0.3은 데이터가 많고 모델 튜닝 단계일때, 0.1은 데이터가 매우 적을 때 사용\n",
    "### random_state는 난수 시드로 동일한 결과를 얻기 위한 이정표라고 생각하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(original_x, original_y, test_size=0.3, random_state=42)\n",
    "# 종속변수와 독립변수의 결합\n",
    "### axis는 데이터셋 결합 방향으로, 0은 행 방향, 1은 열 방향\n",
    "xy_train = pd.concat(objs=[X_train, y_train], axis = 1)\n",
    "# 회귀분석 식\n",
    "formula = \"\"\"\n",
    "Hammer_price ~ Claim_price + Auction_count\n",
    "       + Auction_miscarriage_count + Total_land_gross_area\n",
    "       + Total_land_real_area + Total_land_auction_area\n",
    "       + Total_building_area + Total_building_auction_area\n",
    "       + Total_appraisal_price + Minimum_sales_price + Total_floor\n",
    "       + Current_floor + point_x + point_y\n",
    "\"\"\"\n",
    "# 회귀 모델 데이터 학습 및 X_valid로 예측\n",
    "import statsmodels.api as sm  \n",
    "model = sm.OLS.from_formula(formula, data = xy_train)  \n",
    "model = model.fit()  \n",
    "predict = model.predict(X_valid)  \n",
    "# RMSE는 큰 이상치를 잡아내는 효과적인 도구 \n",
    "### 루트(평균 - 예상), 값이 많으면 내부에서 더하고 개수로 나눠줌\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RMSE = mean_squared_error(y_valid, predict)**0.5\n",
    "RMSE\n",
    "# 제출용 데이터 학습 및 정리\n",
    "original_xy = pd.concat([original_x, original_y], axis=1)\n",
    "original_xy.head()\n",
    "\n",
    "model = sm.OLS.from_formula(formula, data = original_xy)  \n",
    "model = model.fit()  \n",
    "predict = model.predict(test)\n",
    "\n",
    "predict.head()\n",
    "\n",
    "submission['Hammer_price'] = predict\n",
    "submission.head()\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "# 종속변수 분포 확인\n",
    "### 데이터 개수에 따라 bins 사용 기준 달라짐 bins 20~30(데이터 ~1000), 30~50(데이터 ~10000), 50~100(데이터 ~100000)\n",
    "### bins=\"auto\"도 가능\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.histplot(data=train, x=\"Hammer_price\", bins=100)\n",
    "plt.show()\n",
    "# x축 Auction_count, y축 Hammer_price로 하는 막대 그래프\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "x = train['Auction_count']\n",
    "y = train['Hammer_price']\n",
    "\n",
    "ax.set_xlabel('Auction_count')\n",
    "ax.set_ylabel('Hammer_price')\n",
    "\n",
    "ax.bar(x,y)\n",
    "plt.show()\n",
    "# 부산에서 7억 이상인 아파트 시군구 분포 확인\n",
    "train_busan = train[train['addr_do'] == '부산']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,5), dpi = 100)\n",
    "\n",
    "x = train_busan[train_busan['Hammer_price']>700000000]['addr_si'].value_counts().index\n",
    "y = train_busan[train_busan['Hammer_price']>700000000]['addr_si'].value_counts().values\n",
    "\n",
    "ax.tick_params(axis = 'x', rotation=45)\n",
    "ax.bar(x,y)\n",
    "plt.show()\n",
    "# 서울에서 30억 이상인 아파트 시군구 분포 확인\n",
    "train_seoul = train[train['addr_do'] == '서울']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,5), dpi = 100)\n",
    "\n",
    "x = train_seoul[train_seoul['Hammer_price']>3000000000]['addr_si'].value_counts().index\n",
    "y = train_seoul[train_seoul['Hammer_price']>3000000000]['addr_si'].value_counts().values\n",
    "\n",
    "ax.tick_params(axis = 'x', rotation=45)\n",
    "ax.bar(x,y)\n",
    "plt.show()\n",
    "# 거래 횟수와 가격의 관계 선그래프\n",
    "fig, ax = plt.subplots(figsize = (7,5))\n",
    "\n",
    "x_seq = result[result['Auction_key']==3]['Auction_seq']\n",
    "y_min_price= result[result['Auction_key']==3]['Minimum_sales_price']\n",
    "y_price= result[result['Auction_key']==3]['Appraisal_price']\n",
    "\n",
    "ax.set_xlabel('Auction_seq')\n",
    "ax.set_ylabel('Price')\n",
    "\n",
    "ax.plot(x_seq,y_min_price)\n",
    "ax.plot(x_seq,y_price)\n",
    "ax.legend(['Minimum_sales_price','Appraisal_price'])\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "x_seq = result[result['Auction_key']==5]['Auction_seq']\n",
    "y_min_price= result[result['Auction_key']==5]['Minimum_sales_price']\n",
    "y_price= result[result['Auction_key']==5]['Appraisal_price']\n",
    "\n",
    "ax.set_xlabel('Auction_seq')\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_xticks([1,2,3,4])\n",
    "\n",
    "ax.plot(x_seq,y_min_price)\n",
    "ax.plot(x_seq,y_price)\n",
    "ax.legend(['Minimum_sales_price','Appraisal_price'])\n",
    "plt.show()\n",
    "# 산점도로 감정가와 최저매각가 관계 확인\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "y_price_comparison = result['Appraisal_price']\n",
    "y_minprice_comparison = result['Minimum_sales_price']\n",
    "\n",
    "ax.set_xlabel('min_price_comparison')\n",
    "ax.set_ylabel('price_comparisonice')\n",
    "\n",
    "plt.xlim(0, 0.5e10)\n",
    "plt.ylim(0, 0.8e10)\n",
    "\n",
    "ax.scatter(y_minprice_comparison,y_price_comparison)\n",
    "plt.show()\n",
    "# 총 토지 경매 면적과 총 토지 실면적 관계 확인\n",
    "## 경매 면적 증가할수록 실면적도 증가\n",
    "### 다중공산성 확인됨, 다중공산성이란 비슷하거나 같은 역할을 하는 독립변수가 있으면 회귀 부넛ㄱ에서 계수 추정이 불안정해져서 제거 요소\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "area = train[['Total_land_auction_area','Total_land_real_area']]\n",
    "\n",
    "ax.scatter(x = area['Total_land_auction_area'], y = area['Total_land_real_area'])\n",
    "\n",
    "plt.xlabel('Total_land_auction_area')\n",
    "plt.ylabel('Total_land_real_area')\n",
    "\n",
    "plt.xlim([0,250])\n",
    "plt.ylim([0,250])\n",
    "\n",
    "plt.show()\n",
    "# 마지막 행 제외한 중복값 제거\n",
    "## 경매는 여러번 진행되며 가격이 떨어지기 때문에 최종가격만 결과에 포함되도록 처리\n",
    "clean_result = result.drop_duplicates(subset = 'Auction_key', keep = 'last')\n",
    "clean_result\n",
    "# train 데이터와 clean_result값 결합\n",
    "### how에서 outer는 합집합, left, right은 위치한 데이터 기준으로 결합\n",
    "### on에서 어떤 열 기준으로 결합할지 선택, 기준으로 삼지 않은 열은 2개가 생길수도 있음\n",
    "train_result = train.merge(clean_result, how = 'left', on = 'Auction_key')\n",
    "train_result.head(3)\n",
    "# 연도 정보 추출\n",
    "train_result['Auction_date'] = pd.to_datetime(train_result['Auction_date'], errors = 'ignore')\n",
    "    \n",
    "train_result['year'] = train_result['Auction_date'].dt.year\n",
    "train_result['year']\n",
    "# 범주형 데이터를 이진 변수로 생성\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(train_result[['Bid_class']])\n",
    "onehot_data = ohe.transform(train_result[['Bid_class']])\n",
    "onehot_frame = pd.DataFrame(onehot_data, columns = ohe.categories_[0])\n",
    "\n",
    "train_result = pd.concat([train_result, onehot_frame], axis = 1)\n",
    "\n",
    "train_result = train_result.drop(['Bid_class', '일괄'], axis=1)\n",
    "train_result.head(3)\n",
    "# 범주형 데이터를 숫자 변수로 생성\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(train_result['Auction_results'])\n",
    "train_result['Auction_results'] = le.transform(train_result['Auction_results'])\n",
    "train_result['Auction_results'].value_counts()\n",
    "# 결측값에 최빈값 할당\n",
    "print('addr_bunji1의 결측값은', train_result['addr_bunji1'].isnull().sum(), '개 입니다.')\n",
    "freq = train_result['addr_bunji1'].value_counts().index[0]\n",
    "train_result['addr_bunji1'] = train_result['addr_bunji1'].fillna(freq)\n",
    "print('addr_bunji1의 결측값은', train_result['addr_bunji1'].isnull().sum(), '개 입니다.')\n",
    "# 상관계수 확인\n",
    "### 1에 가까울수록 양의 선형 관계, -1에 가까울수록 음의 선형 관계, 0에 가까울수록 관계없음\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (16,12), dpi = 100, constrained_layout=True)\n",
    "sns.heatmap(train_result.corr(), annot = True)\n",
    "plt.show()\n",
    "# 다중공산성 의심 변수 제거\n",
    "highcorr_area = ['Total_land_real_area', 'Total_land_auction_area', 'Total_building_area', 'Total_building_auction_area']\n",
    "train_result = train_result.drop(highcorr_area, axis =1)\n",
    "# 종속변수와 상관계수 높았던 피처 저장하여 변수 저장\n",
    "selected = ['Appraisal_price', 'Total_appraisal_price', 'Minimum_sales_price_x', 'Hammer_price']\n",
    "\n",
    "selected_train = train_result[selected]\n",
    "selected_train.head(3)\n",
    "\n",
    "# year 피처 생성 및 날짜 피처 제거\n",
    "train['Final_auction_date'] = pd.to_datetime(train['Final_auction_date'], errors = 'ignore')\n",
    "train['year'] = train['Final_auction_date'].dt.year\n",
    "date_col = ['Appraisal_date', 'First_auction_date', 'Final_auction_date', 'Preserve_regist_date', 'Close_date']\n",
    "train = train.drop(date_col, axis= 1)\n",
    "\n",
    "# 최빈값으로 결측값 보완\n",
    "addr_freq = train['addr_bunji1'].value_counts().index[0]\n",
    "road_freq = train['road_bunji1'].value_counts().index[0]\n",
    "train['addr_bunji1'] = train['addr_bunji1'].fillna(addr_freq)\n",
    "train['road_bunji1'] = train['road_bunji1'].fillna(road_freq)\n",
    "\n",
    "# 결측값 많은 피처 제거\n",
    "much_null = ['addr_li', 'addr_bunji2', 'Specific', 'road_bunji2']\n",
    "train = train.drop(much_null, axis = 1)\n",
    "\n",
    "# Hammer_price를 제외하고 상관계수가 높았던 피처 제거\n",
    "highcorr_col = ['Total_land_real_area', 'Total_land_auction_area', 'Total_building_area', 'Total_building_auction_area']\n",
    "train = train.drop(highcorr_col, axis =1)\n",
    "\n",
    "result['result_year'] = pd.to_datetime(result['Auction_date'], errors = 'ignore').dt.year\n",
    "\n",
    "result = result[result['result_year'] >= 2014]\n",
    "\n",
    "need_merge = result[['Auction_key', 'Auction_results']].drop_duplicates(subset = 'Auction_key', keep = 'last')\n",
    "need_merge = need_merge.reset_index(drop = True)\n",
    "need_merge.head(5)\n",
    "\n",
    "result.head(43)\n",
    "# Auction_key 기준으로 그룹화\n",
    "### 그룹화시 판단기준 1. valid점수가 낮아지는지 2. 분산 낮아지는지 3. 평균끼리 차이 명확해졌는지 4. 샘플 수 충분한지\n",
    "appraisal_min = result.groupby('Auction_key')['Appraisal_price'].min()\n",
    "need_merge['appraisal_min'] = appraisal_min.values\n",
    "need_merge.head()\n",
    "\n",
    "sales_min = result.groupby('Auction_key')['Minimum_sales_price'].min()\n",
    "need_merge['sales_min'] = sales_min.values\n",
    "need_merge.head()\n",
    "\n",
    "max_seq = result.groupby('Auction_key')['Auction_seq'].max()\n",
    "need_merge['max_seq'] = max_seq.values\n",
    "need_merge.head(2)\n",
    "# 결과가 유찰 횟수 결합\n",
    "failed_auction = result[result['Auction_results'] == '유찰']\n",
    "auction_count = failed_auction.groupby('Auction_key')['Auction_results'].count()\n",
    "auction_result = need_merge.join(auction_count, on = 'Auction_key', how = 'left', lsuffix = '_left', rsuffix = '_right')\n",
    "auction_result.head(5)\n",
    "# 결측치 0으로 채우기\n",
    "auction_result = auction_result.fillna(0)\n",
    "auction_result['Auction_results_right'].isnull().sum()\n",
    "\n",
    "# 첫 경매시 최저매각가격\n",
    "first_price = result.groupby('Auction_key')['Minimum_sales_price'].max().values # 첫\n",
    "# 마지막 경매시 최저매각가격\n",
    "last_price = result.groupby('Auction_key')['Minimum_sales_price'].min().values # 최종\n",
    "\n",
    "change_rate = (last_price - first_price) / first_price * 100  \n",
    "auction_result['change_rate'] = change_rate  \n",
    "auction_result.head(2)   \n",
    "\n",
    "train_result = train.merge(auction_result, on = 'Auction_key', how = 'left')\n",
    "train_result.head(2)\n",
    "# 유찰 횟수별 낙찰가 추이 확인\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot = train_result.pivot_table(index = 'year', columns = 'Auction_results_right', values = 'Hammer_price',  aggfunc = 'sum')\n",
    "pivot.plot(figsize = (8,6))\n",
    "plt.show()\n",
    "# 빈도값 추출\n",
    "objects = ['Auction_class', 'Bid_class', 'Appraisal_company', 'Final_result', 'Creditor', 'addr_do', 'addr_si', 'addr_dong', 'addr_san', 'addr_etc', 'Apartment_usage', 'Share_auction_YorN', 'road_name', 'Close_result', 'Auction_results_left']\n",
    "\n",
    "for col in objects:\n",
    "    print(train_result[col].value_counts()[:3])\n",
    "    print(len(train_result[col].value_counts()))\n",
    "    print('--------------------------')\n",
    "\n",
    "check_company = train_result['Appraisal_company'].str[:-2][:50]\n",
    "print(check_company)\n",
    "# 종속변수 평균으로 시군구별 낙찰가 그래프 확인\n",
    "import matplotlib.pyplot as plt\n",
    "​\n",
    "plt.figure(figsize=(4, 8), dpi=100, constrained_layout=True)\n",
    "addr_index = train_result.groupby('addr_si')['Hammer_price'].mean().sort_values().index\n",
    "addr_value = train_result.groupby('addr_si')['Hammer_price'].mean().sort_values().values\n",
    "​\n",
    "plt.xlabel('Hammer_price')\n",
    "plt.ylabel('addr_si')\n",
    "ax = plt.barh(y=addr_index, width=addr_value)\n",
    "plt.show()\n",
    "# 평균낙찰가 높은 지역 피처 생성\n",
    "high_landprice = train_result.groupby('addr_si')['Hammer_price'].mean().sort_values(ascending = False).index[:6]\n",
    "\n",
    "train_result['low_high'] = train_result['addr_si'].apply(lambda x : 1 if x in high_landprice else 0)\n",
    "train_result['low_high'].value_counts()\n",
    "# 원핫인코딩 (이진변수로 변환)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "onehot_bid = ohe.fit_transform(train_result[['Bid_class']])\n",
    "onehot_frame = pd.DataFrame(onehot_bid, columns = ohe.categories_[0])\n",
    "train_result = pd.concat([train_result, onehot_frame], axis = 1)\n",
    "\n",
    "train_result = train_result.drop(['Bid_class', '일괄'], axis = 1)\n",
    "train_result.head(2)\n",
    "# 라벨 인코딩 (변수 숫자로 할당)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_col = ['Auction_class', 'addr_do', 'addr_san', 'Share_auction_YorN', 'Auction_results_left', 'Apartment_usage']\n",
    "\n",
    "for i in label_col:\n",
    "    le = LabelEncoder()\n",
    "    train_result[i] = le.fit_transform(train_result[i])\n",
    "# 피처 제거\n",
    "drop_list = ['Close_result', 'Final_result', 'addr_dong', 'addr_etc', 'road_name', 'Appraisal_company', 'Creditor', 'addr_si']\n",
    "\n",
    "train_result = train_result.drop(drop_list, axis = 1)\n",
    "#---------------한번 끝까지 진행--------------------\n",
    "# year 피처 생성 및 날짜 피처 제거\n",
    "train['Final_auction_date'] = pd.to_datetime(train['Final_auction_date'], errors = 'ignore')\n",
    "train['year'] = train['Final_auction_date'].dt.year\n",
    "date_col = ['Appraisal_date', 'First_auction_date', 'Final_auction_date', 'Preserve_regist_date', 'Close_date']\n",
    "train = train.drop(date_col, axis= 1)\n",
    "\n",
    "# 최빈값으로 결측값 보완\n",
    "addr_freq = train['addr_bunji1'].value_counts().index[0]\n",
    "road_freq = train['road_bunji1'].value_counts().index[0]\n",
    "train['addr_bunji1'] = train['addr_bunji1'].fillna(addr_freq)\n",
    "train['road_bunji1'] = train['road_bunji1'].fillna(road_freq)\n",
    "\n",
    "# 결측값이 많은 피처 제거\n",
    "much_null = ['addr_li', 'addr_bunji2', 'Specific', 'road_bunji2']\n",
    "train = train.drop(much_null, axis = 1)\n",
    "\n",
    "# Target을 제외하고 상관계수가 높았던 피처 제거\n",
    "highcorr_col = ['Total_land_real_area', 'Total_land_auction_area', 'Total_building_area', 'Total_building_auction_area']\n",
    "train = train.drop(highcorr_col, axis =1)\n",
    "\n",
    "# 데이터 분석 과정에서 제거하기로 결정한 피처 제거\n",
    "drop_list = ['Close_result', 'Final_result', 'addr_dong', 'addr_etc', 'road_name', 'Appraisal_company', 'Creditor', 'addr_si']\n",
    "train = train.drop(drop_list, axis = 1)\n",
    "\n",
    "# result_year 변수 생성 및 2014년 이후 데이터만 사용\n",
    "result['result_year'] = pd.to_datetime(result['Auction_date'], errors = 'ignore').dt.year\n",
    "result = result[result['result_year'] >= 2014]\n",
    "\n",
    "# 마지막 데이터 추출\n",
    "need_merge = result[['Auction_key', 'Auction_results']].drop_duplicates(subset = 'Auction_key', keep = 'last')\n",
    "need_merge = need_merge.reset_index(drop = True)\n",
    "\n",
    "# 감정가 최솟값 결합\n",
    "appraisal_min = result.groupby('Auction_key')['Appraisal_price'].min()\n",
    "need_merge['appraisal_min'] = appraisal_min.values\n",
    "\n",
    "# 최저매각가격 최솟값 결합\n",
    "sales_min = result.groupby('Auction_key')['Minimum_sales_price'].min()\n",
    "need_merge['sales_min'] = sales_min.values\n",
    "\n",
    "# 경매횟수의 최대값 가져오기\n",
    "max_seq = result.groupby('Auction_key')['Auction_seq'].max()\n",
    "need_merge['max_seq'] = max_seq.values\n",
    "\n",
    "# 경매결과가 유찰인 횟수 가져오기\n",
    "failed_auction = result[result['Auction_results'] == '유찰']\n",
    "auction_count = failed_auction.groupby('Auction_key')['Auction_results'].count()\n",
    "auction_result = need_merge.join(auction_count, on = 'Auction_key', how = 'left', lsuffix = '_left', rsuffix = '_right')\n",
    "\n",
    "# auction_results_right 결측치 보완\n",
    "null_indice = auction_result[auction_result['Auction_results_right'].isnull()].index\n",
    "auction_result.loc[null_indice, 'Auction_results_right'] = 0\n",
    "\n",
    "# 증감률 피처 생성\n",
    "last_price = result.groupby('Auction_key')['Minimum_sales_price'].min().values\n",
    "first_price = result.groupby('Auction_key')['Minimum_sales_price'].max().values\n",
    "auction_result['change_rate'] = (last_price - first_price) / first_price * 100\n",
    "\n",
    "# 데이터 결합\n",
    "train_result = train.merge(auction_result, on = 'Auction_key', how = 'left')\n",
    "train_result.head(2)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "onehot_bid = ohe.fit_transform(train_result[['Bid_class']])\n",
    "onehot_frame = pd.DataFrame(onehot_bid, columns = ohe.categories_[0])\n",
    "train_result = pd.concat([train_result, onehot_frame], axis = 1)\n",
    "\n",
    "train_result = train_result.drop(['Bid_class', '일괄'], axis = 1)\n",
    "train_result.head(2)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_col = ['Auction_class', 'addr_do', 'addr_san', 'Share_auction_YorN', 'Auction_results_left', 'Apartment_usage']\n",
    "\n",
    "for label in label_col:\n",
    "    le = LabelEncoder()\n",
    "    train_result[label] = le.fit_transform(train_result[label])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x = train_result.drop(['Hammer_price', 'Auction_key'], axis = 1)\n",
    "train_y = train_result['Hammer_price']\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_x, train_y, test_size=0.3, random_state=42)\n",
    "\n",
    "import gc\n",
    "\n",
    "del need_merge\n",
    "del auction_result\n",
    "del train_result\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "ols = sm.OLS(y_train, x_train)\n",
    "results = ols.fit()\n",
    "valid_pred = results.predict(x_valid)\n",
    "\n",
    "check_mse = root_mean_squared_error(y_valid, valid_pred)\n",
    "check_mse\n",
    "\n",
    "results.summary()\n",
    "#--------------------설계된 피처 조합/학습 XGB/LGBM으로 수행\n",
    "# year 피처 생성 및 날짜 피처 제거\n",
    "train['Final_auction_date'] = pd.to_datetime(train['Final_auction_date'], errors='ignore')\n",
    "train['year'] = train['Final_auction_date'].dt.year\n",
    "\n",
    "date_col = ['Appraisal_date', 'First_auction_date', 'Final_auction_date',\n",
    "            'Preserve_regist_date', 'Close_date']\n",
    "train = train.drop(date_col, axis=1)\n",
    "\n",
    "# 최빈값으로 결측값 보완\n",
    "addr_freq = train['addr_bunji1'].value_counts().index[0]\n",
    "road_freq = train['road_bunji1'].value_counts().index[0]\n",
    "\n",
    "train['addr_bunji1'] = train['addr_bunji1'].fillna(addr_freq)\n",
    "train['road_bunji1'] = train['road_bunji1'].fillna(road_freq)\n",
    "\n",
    "# 결측값 많은 피처 제거\n",
    "much_null = ['addr_li', 'addr_bunji2', 'Specific', 'road_bunji2']\n",
    "train = train.drop(much_null, axis=1)\n",
    "\n",
    "# Target을 제외하고 상관계수가 높았던 피처 제거\n",
    "highcorr_col = ['Total_land_real_area', 'Total_land_auction_area',\n",
    "                'Total_building_area', 'Total_building_auction_area']\n",
    "train = train.drop(highcorr_col, axis=1)\n",
    "\n",
    "# 데이터 분석 과정에서 제거하기로 결정한 피처 제거\n",
    "drop_list = ['Close_result', 'Final_result', 'addr_dong', 'addr_etc',\n",
    "             'road_name', 'Appraisal_company', 'Creditor', 'addr_si']\n",
    "train = train.drop(drop_list, axis=1)\n",
    "\n",
    "# year 피처 생성 및 날짜 피처 제거\n",
    "test['Final_auction_date'] = pd.to_datetime(test['Final_auction_date'], errors = 'ignore')\n",
    "test['year'] = test['Final_auction_date'].dt.year\n",
    "date_col = ['Appraisal_date', 'First_auction_date', 'Final_auction_date', 'Preserve_regist_date', 'Close_date']\n",
    "test = test.drop(date_col, axis= 1)\n",
    "\n",
    "# 최빈값으로 결측값 보완\n",
    "addr_freq = train['addr_bunji1'].value_counts().index[0]\n",
    "road_freq = train['road_bunji1'].value_counts().index[0]\n",
    "test['addr_bunji1'] = test['addr_bunji1'].fillna(addr_freq)\n",
    "test['road_bunji1'] = test['road_bunji1'].fillna(road_freq)\n",
    "\n",
    "# 결측값 많은 피처 제거\n",
    "much_null = ['addr_li', 'addr_bunji2', 'Specific', 'road_bunji2']\n",
    "test = test.drop(much_null, axis = 1)\n",
    "\n",
    "# Target을 제외하고 상관계수가 높았던 피처 제거\n",
    "highcorr_col = ['Total_land_real_area', 'Total_land_auction_area', 'Total_building_area', 'Total_building_auction_area']\n",
    "test = test.drop(highcorr_col, axis =1)\n",
    "\n",
    "# 데이터 분석 과정에서 제거하기로 결정한 피처 제거\n",
    "drop_list = ['Close_result', 'Final_result', 'addr_dong', 'addr_etc', 'road_name', 'Appraisal_company', 'Creditor', 'addr_si']\n",
    "test = test.drop(drop_list, axis = 1)\n",
    "\n",
    "# result_year 변수 생성 및 2014년 이후 데이터만 사용\n",
    "result['result_year'] = pd.to_datetime(result['Auction_date'], errors = 'ignore').dt.year\n",
    "result = result[result['result_year'] >= 2014]\n",
    "\n",
    "# 마지막 데이터 추출\n",
    "need_merge = result[['Auction_key', 'Auction_results']].drop_duplicates(subset = 'Auction_key', keep = 'last')\n",
    "need_merge = need_merge.reset_index(drop = True)\n",
    "\n",
    "# 감정가 최솟값 결합\n",
    "appraisal_min = result.groupby('Auction_key')['Appraisal_price'].min()\n",
    "need_merge['appraisal_min'] = appraisal_min.values\n",
    "\n",
    "# 최저매각가격 최솟값 결합\n",
    "sales_min = result.groupby('Auction_key')['Minimum_sales_price'].min()\n",
    "need_merge['sales_min'] = sales_min.values\n",
    "\n",
    "# 경매횟수의 최대값 가져오기\n",
    "max_seq = result.groupby('Auction_key')['Auction_seq'].max()\n",
    "need_merge['max_seq'] = max_seq.values\n",
    "\n",
    "# 경매결과가 유찰인 횟수 가져오기\n",
    "failed_auction = result[result['Auction_results'] == '유찰']\n",
    "auction_count = failed_auction.groupby('Auction_key')['Auction_results'].count()\n",
    "auction_result = need_merge.join(auction_count, on = 'Auction_key', how = 'left', lsuffix = '_left', rsuffix = '_right')\n",
    "\n",
    "# auction_results_right 결측치 보완\n",
    "null_indice = auction_result[auction_result['Auction_results_right'].isnull()].index\n",
    "auction_result.loc[null_indice, 'Auction_results_right'] = 0\n",
    "\n",
    "# 증감률 피처 생성\n",
    "last_price = result.groupby('Auction_key')['Minimum_sales_price'].min().values\n",
    "first_price = result.groupby('Auction_key')['Minimum_sales_price'].max().values\n",
    "auction_result['change_rate'] = (last_price - first_price) / first_price * 100\n",
    "\n",
    "# 데이터 결합\n",
    "train_result = train.merge(auction_result, on = 'Auction_key', how = 'left')\n",
    "test_result = test.merge(auction_result, on = 'Auction_key', how = 'left')\n",
    "train_result.head(2)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown = 'ignore')\n",
    "onehot_train = ohe.fit_transform(train_result[['Bid_class']])\n",
    "onehot_frame = pd.DataFrame(onehot_train, columns = ohe.categories_[0])\n",
    "train_result = pd.concat([train_result, onehot_frame], axis = 1)\n",
    "\n",
    "train_result = train_result.drop(['Bid_class', '일괄'], axis = 1)\n",
    "train_result.head(2)\n",
    "\n",
    "test_onehot = ohe.transform(test_result[['Bid_class']])\n",
    "onehot_frame = pd.DataFrame(test_onehot, columns = ohe.categories_[0])\n",
    "test_result = pd.concat([test_result, onehot_frame], axis = 1)\n",
    "\n",
    "test_result = test_result.drop(['Bid_class', '일괄'], axis = 1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "label_col = ['Auction_class', 'addr_do', 'addr_san', 'Share_auction_YorN', 'Auction_results_left', 'Apartment_usage']\n",
    "\n",
    "for col in label_col:\n",
    "    le = LabelEncoder()\n",
    "    train_result[col] = le.fit_transform(train_result[col])\n",
    "    \n",
    "    for label in np.unique(test_result[col]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_result[col] = le.transform(test_result[col])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x = train_result.drop(['Hammer_price', 'Auction_key'], axis = 1)\n",
    "train_y = train_result['Hammer_price']\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_x, train_y, test_size=0.3, random_state=42)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(random_state = 42)\n",
    "xgb.fit(x_train, y_train)\n",
    "valid_pred = xgb.predict(x_valid)\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "root_mean_squared_error(y_valid, valid_pred)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_grid = XGBRegressor(random_state = 42)\n",
    "\n",
    "params = {'n_estimators': [15, 30],\n",
    "          'max_depth': [3, 8]}\n",
    "\n",
    "greedy_CV = GridSearchCV(xgb_grid, param_grid=params, cv = 2, n_jobs = -1)\n",
    "greedy_CV.fit(x_train, y_train)\n",
    "\n",
    "xgb_best_model = greedy_CV.best_estimator_\n",
    "valid_pred = xgb_best_model.predict(x_valid)\n",
    "root_mean_squared_error(y_valid, valid_pred)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
